#!/usr/bin/env perl

use strict;
use warnings;
use FindBin qw($Bin);
use lib ( -d "$Bin/../lib/perl5" ? "$Bin/../lib/perl5" : "$Bin/../lib" );
use Log::Log4perl qw(:levels);
use DateTime::Format::Strptime q(strptime);
use Getopt::Long;
use Pod::Usage;
use Readonly;
use List::MoreUtils qw(any);
use Try::Tiny;
use Carp;
use Perl6::Slurp;

use WTSI::DNAP::Warehouse::Schema;

our $VERSION = '0';

Readonly::Scalar my $REPORT_COLUMN_DELIM    => qq[\t];
Readonly::Scalar my $REPORT_DATA_DELIM      => q[,];
Readonly::Scalar my $REPORT_READ_NAME_DELIM => q[/];
Readonly::Scalar my $REPORT_DATE_FORMAT     => q[%Y%m%d];
Readonly::Scalar my $REPORT_NA_STRING       => q[NA];

Readonly::Scalar my $EXT_METRICS_RS_NAME    => q[IseqExternalProductMetric];
Readonly::Scalar my $MANIFEST_UPLOAD_STATUS_SUCCESS  => 'SUCCESS';
Readonly::Scalar my $MANIFEST_UPLOAD_STATUS_ANNULLED => 'ANNULLED';

# Mapping of database column names to report column names
Readonly::Hash my %MONIKER_MAP => {

  UKB_sampleID => 'supplier_sample_name',
  plateID => 'plate_barcode',
  uCRAM_filenames => 'file_name',
  uCRAM_full_paths => 'file_path',
  uCRAM_Sanger_validation_MD5 => 'md5_staging',
  uCRAM_SBG_validation_MD5 => 'md5',
  uCRAM_MD5_validation => 'md5_validation',
  uCRAM_validation_date => 'md5_validation_date',
  uCRAM_format_validation => 'format_validation',
  uCRAM_upload_date => 'upload_date',
  Upload_status => 'upload_status',
  Seq_Start_date => 'sequencing_start_date',
  Instrument_ID => 'instrument_id',
  Flowcell_ID => 'flowcell_id',
  Sample_data_annotation => 'annotation',
  QC_date => 'processing_start_date',
  'Fractional_coverage_at_>=_15X' => 'target_autosome_gt_coverage_threshold',
  'Fractional_coverage_at_>=_15X_pass' => 'target_autosome_gt_coverage_threshold_assessment',
  FREEMIX_fraction => 'verify_bam_id_score',
  FREEMIX_pass =>  'verify_bam_id_score_assessment',
  Minimum_read_length => 'min_read_length',
  Yield => 'yield',
  Read_count => 'num_reads',
  GC_fraction_first_read => 'gc_fraction_forward_read',
  GC_fraction_second_read => 'gc_fraction_reverse_read',
  PreAdapter_minimum_TOTAL_QSCORE => 'pre_adapter_min_total_qscore',
  BaitBias_minimum_TOTAL_QSCORE => 'ref_bias_min_total_qscore',
  Fraction_properly_paired_reads_pass => 'target_proper_pair_mapped_reads_assessment',
  Fraction_properly_paired_reads => 'target_proper_pair_mapped_reads_fraction',
  Insert_size_mean => 'insert_size_mean',
  Insert_size_SD => 'insert_size_std',
  Adapter_contamination_fraction => 'adapter_contamination',
  Adapter_content_pass => 'adapter_contamination_assessment',
  Basecall_qualities_q20_yield => 'yield_q20',
  Basecall_qualities_q30_yield => 'yield_q30',
  Basic_Statistics => 'basic_statistics_assessement',
  Overrepresented_Sequences => 'overrepresented_sequences_assessement',
  Per_Base_N_Content => 'n_content_per_base_assessement',
  Per_Base_Sequence_Content => 'sequence_content_per_base_assessement',
  Per_Base_Sequence_Quality => 'sequence_quality_per_base_assessement',
  Per_Sequence_GC_Content => 'gc_content_per_sequence_assessement',
  Per_Sequence_Quality_Scores => 'quality_scores_per_sequence_assessement',
  Sequence_Duplication_Levels => 'sequence_duplication_levels_assessement',
  Sequence_Length_Distribution => 'sequence_length_distribution_assessement',
  Fractional_sequence_error_rate => 'sequence_error_rate',
  Analysis_start_date => 'analysis_start_date',
  FastQC_assessment => 'fastqc_overall_assessment',
  Double_Error_Fraction => 'double_error_fraction',
  Two_test_contamination_pass => 'contamination_assessment',
  Fractional_NRD => 'nrd',
  NRD_pass => 'nrd_assessment',
  Analysis_end_date => 'analysis_end_date',
  Computed_sex => 'sex_computed',
  Reported_sex => 'sex_reported',
  Data_QC_status => 'qc_overall_assessment',
  Processing_Status => 'processing_status',
  QC_status => 'qc_status',
  Transfer_Date => 'archival_date',
  Data_archive_confirmed_date => 'archive_confirmation_date',
  Archive_ID_for_data_product => 'id_archive_product',
  Phase2_end_date => 'phase2_end_date',
  Input_Files_Status => 'input_files_status',
  Intermediate_Files_Status => 'intermediate_files_status',
  Output_Files_Status => 'output_files_status',
  Input_Status_Override_Ref => 'input_status_override_ref',
  Intermediate_Status_Override_Ref => 'intermediate_status_override_ref',
  Output_Status_Override_Ref => 'output_status_override_ref',
};

Readonly::Hash my %DICTIONARY_VALUES => {
  md5_validation                             => [qw(PASS FAIL)],
  format_validation                          => [qw(PASS FAIL)],
  upload_status                              => [qw(PASS FAIL)],
  processing_status                          => [qw(PASS HOLD INSUFFICIENT FAIL)],
  qc_status                                  => [qw(PASS HOLD INSUFFICIENT FAIL)],
  qc_overall_assessment                      => [qw(PASS FAIL)],
  contamination_assessment                   => [qw(PASS FAIL)],
  target_proper_pair_mapped_reads_assessment => [qw(PASS FAIL)],
  verify_bam_id_score_assessment             => [qw(PASS FAIL)],
  nrd_assessment                             => [qw(PASS FAIL), $REPORT_NA_STRING],
  fastqc_overall_assessment                  => [qw(PASS FAIL)],
  adapter_contamination_assessment           => [qw(PASS FAIL WARN)],
  basic_statistics_assessement               => [qw(PASS FAIL WARN)],
  overrepresented_sequences_assessement      => [qw(PASS FAIL WARN)],
  n_content_per_base_assessement             => [qw(PASS FAIL WARN)],
  sequence_quality_per_base_assessement      => [qw(PASS FAIL WARN)],
  gc_content_per_sequence_assessement        => [qw(PASS FAIL WARN)],
  quality_scores_per_sequence_assessement    => [qw(PASS FAIL WARN)],
  sequence_duplication_levels_assessement    => [qw(PASS FAIL WARN)],
  sequence_length_distribution_assessement   => [qw(PASS FAIL WARN)]
};

Readonly::Array my @MUST_HAVE => qw(
  supplier_sample_name
  file_name
  file_path
);

Readonly::Array my @MUST_HAVE4UPLOADED => qw(
  plate_barcode
  md5
  md5_validation
  md5_validation_date
  format_validation
  upload_date
  upload_status
);

Readonly::Array my @MUST_MATCH => qw(
  supplier_sample_name
  file_name
);

Readonly::Array my @MUST_MATCH4UPLOADED => qw(
  md5_staging
  plate_barcode
);

my $dry_run = 1;
my $help;
my $report_url;
my $report_path;

GetOptions (
            'help'          => \$help,
            'dry_run!'      => \$dry_run,
            'report_url=s'  => \$report_url,
            'report_path=s' => \$report_path,
           );

if ($help) { pod2usage(0); }

my $layout = '%d %-5p %c - %m%n';
Log::Log4perl->easy_init({layout => $layout,
                          level  => $INFO,
                          utf8   => 1});
my $logger = Log::Log4perl->get_logger();
$dry_run and $logger->info('DRY RUN');

if ($report_url and $report_path) {
  $logger->fatal('Both --report_url and --report_path cannot be set');
  exit 1;
}
if (not ($report_url or $report_path)) {
  $logger->fatal('Either --report_url or --report_path should be set');
  exit 1;
}

my $schema_wh = WTSI::DNAP::Warehouse::Schema->connect();

my $exit_code = 0;
try {
  $exit_code = main();
} catch {
  $logger->error($_);
  $exit_code = 1;
};

exit $exit_code;

sub main {

  my $lines = _get_lines();
  # Remove and parse the header
  my $column2index_map = _map_db_columns2list_indexes(shift @{$lines});
  my $count = 0;
  my $num_updated = 0;
  my $error_count = 0;

  foreach my $line (@{$lines}) {
    $count++;
    try {
      _save_line2db($line, $column2index_map, $count);
      $num_updated++;
    } catch {
      $logger->error("Report line ${count}: $_");
      $error_count++;
    };
  }

  $logger->info("$count lines in the report");
  if ($num_updated) {
    $dry_run and $logger->info('Database update disabled');
    $logger->info("$num_updated rows updated in the database");
  } else {
    $logger->error('No rows updated in the database');
  }

  return $error_count ? 2 : 0;
}

sub _get_lines {

  my $what = $report_path ? $report_path : "gsutil cat $report_url |";
  $logger->info("Parsing '$what'");
  my @lines = slurp $what, {chomp=>1};

  return \@lines;
}

sub _split_line {
  my $line = shift;
  my @temp = split $REPORT_COLUMN_DELIM, $line;
  my @data = ();
  foreach my $d (@temp) {
    $d and $d =~ s/\A\s+//smx;
    $d and $d =~ s/\s+\Z//smx;
    push @data, $d;
  }
  return @data;
}

sub _split_record {
  my $r = shift;
  ##no critic (RegularExpressions::RequireExtendedFormatting)
  my @data = split /$REPORT_DATA_DELIM/sm, $r;
  return @data;
}

sub _concat_record {
  my @data = @_;
  return join $REPORT_DATA_DELIM, sort @data;
}

sub _parse_date {
  my $date_string = shift;
  return strptime($REPORT_DATE_FORMAT, $date_string);
}

sub _map_db_columns2list_indexes {
  my $header = shift;

  my @column_names = _split_line($header);

  my %map = map { $_ => q[] } values %MONIKER_MAP;
  my $count = 0;
  foreach my $name (@column_names) {
    if (exists $MONIKER_MAP{$name}) {
      $map{$MONIKER_MAP{$name}} = $count;
    }
    $count++;
  }

  my @missing_columns = grep { $map{$_} eq q[] } keys %map;
  @missing_columns and croak
    'Report colums are missing for the following database columns: ' .
    join q[, ], @missing_columns;

  return \%map;
}

sub _validate_restricted_values {
  my $data4update = shift;

  # Validation of report flag values.
  for my $restricted (%DICTIONARY_VALUES) {
    exists $data4update->{$restricted} or next;
    my @read_data = split /$REPORT_DATA_DELIM | $REPORT_READ_NAME_DELIM/smx,
                    $data4update->{$restricted};
    foreach my $d (@read_data) {
      (any { $_ eq $d } @{$DICTIONARY_VALUES{$restricted}})
        or croak sprintf 'Invalid value %s for %s',
                         $data4update->{$restricted}, $restricted;
    }
  }
  return;
}

sub _validate_must_have {
  my ($data, @must_haves) = @_;
  foreach my $must_have_name (@must_haves) {
    defined $data->{$must_have_name} or croak "$must_have_name is undefined";
  }
  return;
}

sub _prune_master_values {
  my ($row, $data4update, @must_match) = @_;

  for my $column_name (@must_match) {
    ($row->$column_name eq $data4update->{$column_name}) or croak
      sprintf 'Mismatch between report %s and db value %s %s for %s',
        $row->$column_name, $data4update->{$column_name},
        $column_name, $row->file_path;
    # Master value exists in the db - no need to update this value
    delete $data4update->{$column_name};
  }

  return;
}

sub _values4update {
  my ($data, $column2index_map) = @_;

  my $data4update = {};
  foreach my $column (keys %{$column2index_map}) {
    my $value = $data->[$column2index_map->{$column}];
    defined $value and ($value ne q[]) and $data4update->{$column} = $value;
  }

  foreach my $column_name (qw(double_error_fraction nrd)) {
    # Column type is float, cannot accept strings.
    if ( $data4update->{$column_name} &&
        ($data4update->{$column_name} eq $REPORT_NA_STRING) ) {
      delete $data4update->{$column_name};
    }
  }

  return $data4update;
}

sub _save_line2db {
  my ($line, $column2index_map, $line_num) = @_;

  my @data = _split_line($line);
  my $data4update = _values4update(\@data, $column2index_map);
  _validate_must_have($data4update, @MUST_HAVE);

  my @paths = _split_record($data4update->{'file_path'});
  $data4update->{'file_path'} = _concat_record(@paths);

  my @file_names = _split_record($data4update->{'file_name'});
  (@file_names == @paths) or croak
    "Discrepancy in number of products in line ${line_num}: $line";
  $data4update->{'file_name'} = _concat_record(@file_names);

  foreach my $date_column_name ( grep { m{_date\Z}xms } keys %{$data4update} ) {
    $data4update->{$date_column_name} =
      _parse_date($data4update->{$date_column_name});
  }

  _validate_restricted_values($data4update);

  try {
    my $transaction = (@paths == 1) ?
      _update_record4uploaded_product($data4update, $column2index_map) :
      _update_create_external_product($data4update, $column2index_map);
    $schema_wh->txn_do($transaction);
  } catch {
    croak "Report line ${line_num}: $_";
  };

  return;
}

sub _find_row {
  my $path = shift;
  my $row = $schema_wh->resultset($EXT_METRICS_RS_NAME)
                      ->search({file_path => $path})->next;
  return $row;
}

sub _update_record4uploaded_product {
  my ($data4update, $column2index_map) = @_;

  _validate_must_have($data4update, @MUST_HAVE4UPLOADED, @MUST_MATCH4UPLOADED);

  ($data4update->{'md5_staging'} eq $data4update->{'md5'}) or
    croak 'md5 mismatch';

  my $path = delete $data4update->{'file_path'};

  my $transaction = sub {
    my $row = _find_row($path);
    $row or croak 'Database record for this report line does not exist';

    # Consistency check between the product status in the db and in the report. 
    ($row->manifest_upload_status eq $MANIFEST_UPLOAD_STATUS_SUCCESS) or
      ($row->manifest_upload_status eq $MANIFEST_UPLOAD_STATUS_ANNULLED) or
      croak 'Upload validated externally for product not flagged as uploaded';

    # Consistency check between existing db values and report values
    _prune_master_values($row, $data4update, @MUST_MATCH, @MUST_MATCH4UPLOADED);

    $dry_run or $row->update($data4update);
  };

  return $transaction;
}

sub _update_create_external_product {
  my ($data4update, $column2index_map) = @_;

  foreach my $column_name (grep { $_ ne 'plate_barcode' } @MUST_HAVE4UPLOADED ) {
    exists $data4update->{$column_name} and croak
      "$column_name report column should not have a value for an external product";
  }

  my $transaction = sub {
    my $row = _find_row($data4update->{'file_path'});
    if ($row) {
      (defined $row->manifest_upload_status) and croak
        'manifest_upload_status db column should not have a value for an external product';
      delete $data4update->{'file_path'};
      _prune_master_values($row, $data4update, @MUST_MATCH);
      $dry_run or $row->update($data4update);
    } else {
      $dry_run or $schema_wh->resultset($EXT_METRICS_RS_NAME)->create($data4update);
    }
  };

  return $transaction;
}

__END__

=head1 NAME

  npg_external_report2ml_warhouse

=head1 SYNOPSIS

  Loads data from a progressive external report to ml warehouse.

=head1 USAGE

  npg_external_report2ml_warhouse --help
  npg_external_report2ml_warhouse --report_url [--no-dry_run]
  npg_external_report2ml_warhouse --report_path [--no-dry_run]

  --dry-run flag is set by default, no ml warehouse database
  update is performed.

=head1 DESCRIPTION

 Loads data from a progressive external report to ml warehouse.
  
=head1 REQUIRED ARGUMENTS

  either --report_backet_url or --report_path should be set

=head1 OPTIONS

  --help        - brief help message
  --dry_run     - boolean flag, true by default
  --report_path - full path of the report on a local file system
  --report_url  - full report URL

=head1 EXIT STATUS

=head1 CONFIGURATION

  If GCP bucket is used, BOTO_CONFIG variable sould be set in the
  environment.

=head1 DIAGNOSTICS

=head1 DEPENDENCIES

=over

=item strict

=item warnings

=item lib

=item FindBin

=item Getopt::Long

=item Pod::Usage

=item WTSI::DNAP::Warehouse::Schema

=item DateTime::Format::Strptime

=item Readonly

=item Carp

=item Try::Tiny

=item File::Slurp

=item List::MoreUtils

=item Perl6::Slurp

=back

=head1 INCOMPATIBILITIES

=head1 BUGS AND LIMITATIONS

=head1 AUTHOR

=over

=item Marina Gourtovaia

=back

=head1 LICENSE AND COPYRIGHT

Copyright (C) 2019 by Genome Research Limited

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
 
